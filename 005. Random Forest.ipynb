{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "x_train = pd.read_csv('data/x_train_norm.csv', sep=';', na_values='?')\n",
    "x_test = pd.read_csv('data/x_test_norm.csv', sep=';', na_values='?')\n",
    "y_train = pd.read_csv('data/y_train.csv', sep=';', header=None, na_values='?')[0]\n",
    "\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "def logloss(act, pred):\n",
    "    epsilon = 1e-15\n",
    "    pred = sp.maximum(epsilon, pred)\n",
    "    pred = sp.minimum(1-epsilon, pred)\n",
    "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
    "    ll = ll * -1.0/len(act)\n",
    "    return ll\n",
    "\n",
    "def scorer_logloss(estimator, X, y):\n",
    "    return logloss(y, estimator.predict_proba(X)[:,1])\n",
    "\n",
    "def revert_scorer_logloss(estimator, X, y):\n",
    "    return -1 * scorer_logloss(estimator, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48055015, -0.45686146, -0.47958079])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=11)\n",
    "cross_val_score(classifier, x_train, y_train, n_jobs=3, scoring=revert_scorer_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'margin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2b8f7b29729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgood_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.95\u001b[0m \u001b[0;31m#1 #0.84\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'margin' is not defined"
     ]
    }
   ],
   "source": [
    "good_idx = margin>-0.95 #1 #0.84\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1200, random_state=11, n_jobs=3)\n",
    "classifier.fit(x_train[good_idx], y_train[good_idx])\n",
    "\n",
    "scorer_logloss(classifier, x_train, y_train)\n",
    "#crosses = cross_val_score(classifier, x_train[good_idx], y_train[good_idx], n_jobs=3, scoring=revert_scorer_logloss)\n",
    "#print np.mean(crosses), crosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit1 = 18000\n",
    "limit2 = 20000\n",
    "xx_train, yy_train = x_train[:limit1], y_train[:limit1]\n",
    "xx_valid, yy_valid = x_train[limit1:limit2], y_train[limit1:limit2]\n",
    "xx_test, yy_test = x_train[limit2:], y_train[limit2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(xx_train, yy_train)\n",
    "clf_probs = clf.predict_proba(xx_test)\n",
    "score = log_loss(y_test, clf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70311082909\n",
      "0.703110980271\n"
     ]
    }
   ],
   "source": [
    "#print log_loss(yy_test, clf_probs)\n",
    "#print logloss(yy_test, clf_probs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs=3)\n",
    "clf.fit(xx_train, yy_train)\n",
    "clf_probs = clf.predict_proba(xx_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(xx_valid, yy_valid)\n",
    "sig_clf_probs = sig_clf.predict_proba(xx_test)\n",
    "sig_score = log_loss(yy_test, sig_clf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.395894551821\n"
     ]
    }
   ],
   "source": [
    "print sig_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_estimators = 25   => sig_score = 0.405327146207\n",
    "n_estimators = 800  => sig_score = 0.395930044979\n",
    "n_estimators = 900  => sig_score = 0.396510874298\n",
    "n_estimators = 1000 => sig_score = 0.39568953636  ->min\n",
    "n_estimators = 1100 => sig_score = 0.39592201604\n",
    "n_estimators = 2000 => sig_score = 0.396165819023\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = sig_clf.predict_proba(x_test)[:,1]  # возвращается думерный массив, нас интересует 2-й стоблец\n",
    "res_df = pd.DataFrame(y_test, columns = ['y'])\n",
    "res_df.to_csv('res/005_rf_1000_Calibrated.csv', sep=';', header=None, index=False)\n",
    "#mlbootcamp=0,4016667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = 20000\n",
    "xx_train, yy_train = x_train[:limit], y_train[:limit]\n",
    "xx_valid, yy_valid = x_train[limit:], y_train[limit:]\n",
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs=3)\n",
    "clf.fit(xx_train, yy_train)\n",
    "#clf_probs = clf.predict_proba(xx_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(xx_valid, yy_valid)\n",
    "#sig_clf_probs = sig_clf.predict_proba(xx_test)\n",
    "#sig_score = log_loss(yy_test, sig_clf_probs)\n",
    "\n",
    "y_test = sig_clf.predict_proba(x_test)[:,1]  # возвращается думерный массив, нас интересует 2-й стоблец\n",
    "res_df = pd.DataFrame(y_test, columns = ['y'])\n",
    "res_df.to_csv('res/005_rf_1000_Calibrated_all.csv', sep=';', header=None, index=False)\n",
    "#mlbootcamp=0,4008066"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
