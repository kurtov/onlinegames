{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "x_train = pd.read_csv('data/x_train_norm.csv', sep=';', na_values='?')\n",
    "x_test = pd.read_csv('data/x_test_norm.csv', sep=';', na_values='?')\n",
    "y_train = pd.read_csv('data/y_train.csv', sep=';', header=None, na_values='?')[0]\n",
    "\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "def logloss(act, pred):\n",
    "    epsilon = 1e-15\n",
    "    pred = sp.maximum(epsilon, pred)\n",
    "    pred = sp.minimum(1-epsilon, pred)\n",
    "    ll = sum(act*sp.log(pred) + sp.subtract(1,act)*sp.log(sp.subtract(1,pred)))\n",
    "    ll = ll * -1.0/len(act)\n",
    "    return ll\n",
    "\n",
    "def scorer_logloss(estimator, X, y):\n",
    "    return logloss(y, estimator.predict_proba(X)[:,1])\n",
    "\n",
    "def revert_scorer_logloss(estimator, X, y):\n",
    "    return -1 * scorer_logloss(estimator, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48055015, -0.45686146, -0.47958079])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=11)\n",
    "cross_val_score(classifier, x_train, y_train, n_jobs=3, scoring=revert_scorer_logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'margin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2b8f7b29729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgood_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.95\u001b[0m \u001b[0;31m#1 #0.84\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgood_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'margin' is not defined"
     ]
    }
   ],
   "source": [
    "good_idx = margin>-0.95 #1 #0.84\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1200, random_state=11, n_jobs=3)\n",
    "classifier.fit(x_train[good_idx], y_train[good_idx])\n",
    "\n",
    "scorer_logloss(classifier, x_train, y_train)\n",
    "#crosses = cross_val_score(classifier, x_train[good_idx], y_train[good_idx], n_jobs=3, scoring=revert_scorer_logloss)\n",
    "#print np.mean(crosses), crosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit1 = 18000\n",
    "limit2 = 20000\n",
    "xx_train, yy_train = x_train[:limit1], y_train[:limit1]\n",
    "xx_valid, yy_valid = x_train[limit1:limit2], y_train[limit1:limit2]\n",
    "xx_test, yy_test = x_train[limit2:], y_train[limit2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf.fit(xx_train, yy_train)\n",
    "clf_probs = clf.predict_proba(xx_test)\n",
    "score = log_loss(y_test, clf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70311082909\n",
      "0.703110980271\n"
     ]
    }
   ],
   "source": [
    "#print log_loss(yy_test, clf_probs)\n",
    "#print logloss(yy_test, clf_probs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs=3)\n",
    "clf.fit(xx_train, yy_train)\n",
    "clf_probs = clf.predict_proba(xx_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(xx_valid, yy_valid)\n",
    "sig_clf_probs = sig_clf.predict_proba(xx_test)\n",
    "sig_score = log_loss(yy_test, sig_clf_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.395894551821\n"
     ]
    }
   ],
   "source": [
    "print sig_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_estimators = 25   => sig_score = 0.405327146207\n",
    "n_estimators = 800  => sig_score = 0.395930044979\n",
    "n_estimators = 900  => sig_score = 0.396510874298\n",
    "n_estimators = 1000 => sig_score = 0.39568953636  ->min\n",
    "n_estimators = 1100 => sig_score = 0.39592201604\n",
    "n_estimators = 2000 => sig_score = 0.396165819023\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = sig_clf.predict_proba(x_test)[:,1]  # возвращается думерный массив, нас интересует 2-й стоблец\n",
    "res_df = pd.DataFrame(y_test, columns = ['y'])\n",
    "res_df.to_csv('res/005_rf_1000_Calibrated.csv', sep=';', header=None, index=False)\n",
    "#mlbootcamp=0,4016667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = 20000\n",
    "xx_train, yy_train = x_train[:limit], y_train[:limit]\n",
    "xx_valid, yy_valid = x_train[limit:], y_train[limit:]\n",
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs=3)\n",
    "clf.fit(xx_train, yy_train)\n",
    "#clf_probs = clf.predict_proba(xx_test)\n",
    "sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=\"prefit\")\n",
    "sig_clf.fit(xx_valid, yy_valid)\n",
    "#sig_clf_probs = sig_clf.predict_proba(xx_test)\n",
    "#sig_score = log_loss(yy_test, sig_clf_probs)\n",
    "\n",
    "y_test = sig_clf.predict_proba(x_test)[:,1]  # возвращается думерный массив, нас интересует 2-й стоблец\n",
    "res_df = pd.DataFrame(y_test, columns = ['y'])\n",
    "res_df.to_csv('res/005_rf_1000_Calibrated_all.csv', sep=';', header=None, index=False)\n",
    "#mlbootcamp=0,4008066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.383845648674 [-0.3850577  -0.3795993  -0.38687994]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "classifier = ensemble.GradientBoostingClassifier(n_estimators=100, random_state=11)\n",
    "\n",
    "crossed = cross_val_score(classifier, x_train, y_train, scoring=revert_scorer_logloss, n_jobs=3)\n",
    "print np.mean(crossed), crossed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=11,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid={'n_estimators': array([ 100,  200,  300,  400,  500,  600,  700,  800,  900, 1000, 1100,\n",
       "       1200])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function revert_scorer_logloss at 0x1168a9b90>, verbose=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators_array = np.linspace(100,1200, 12, dtype=int)\n",
    "\n",
    "classifier = ensemble.GradientBoostingClassifier(random_state=11)\n",
    "grid = GridSearchCV(classifier, \n",
    "                    param_grid={'n_estimators': n_estimators_array},\n",
    "                    scoring=revert_scorer_logloss,\n",
    "                    n_jobs=3)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.032167</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>-0.383846</td>\n",
       "      <td>-0.366154</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'n_estimators': 100}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.385058</td>\n",
       "      <td>-0.367194</td>\n",
       "      <td>-0.379599</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.386880</td>\n",
       "      <td>-0.364508</td>\n",
       "      <td>0.117576</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.986692</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>-0.385233</td>\n",
       "      <td>-0.353730</td>\n",
       "      <td>200</td>\n",
       "      <td>{u'n_estimators': 200}</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.385436</td>\n",
       "      <td>-0.354787</td>\n",
       "      <td>-0.380693</td>\n",
       "      <td>-0.354470</td>\n",
       "      <td>-0.389568</td>\n",
       "      <td>-0.351932</td>\n",
       "      <td>0.115388</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.666521</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>-0.386839</td>\n",
       "      <td>-0.343312</td>\n",
       "      <td>300</td>\n",
       "      <td>{u'n_estimators': 300}</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.387082</td>\n",
       "      <td>-0.344239</td>\n",
       "      <td>-0.381543</td>\n",
       "      <td>-0.344449</td>\n",
       "      <td>-0.391893</td>\n",
       "      <td>-0.341248</td>\n",
       "      <td>0.092624</td>\n",
       "      <td>0.004979</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.265884</td>\n",
       "      <td>0.079153</td>\n",
       "      <td>-0.388662</td>\n",
       "      <td>-0.333696</td>\n",
       "      <td>400</td>\n",
       "      <td>{u'n_estimators': 400}</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.389261</td>\n",
       "      <td>-0.334143</td>\n",
       "      <td>-0.383028</td>\n",
       "      <td>-0.334937</td>\n",
       "      <td>-0.393697</td>\n",
       "      <td>-0.332007</td>\n",
       "      <td>0.040597</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.001237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.978239</td>\n",
       "      <td>0.081821</td>\n",
       "      <td>-0.390381</td>\n",
       "      <td>-0.325172</td>\n",
       "      <td>500</td>\n",
       "      <td>{u'n_estimators': 500}</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.390605</td>\n",
       "      <td>-0.325690</td>\n",
       "      <td>-0.385195</td>\n",
       "      <td>-0.325979</td>\n",
       "      <td>-0.395342</td>\n",
       "      <td>-0.323847</td>\n",
       "      <td>0.183330</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.511245</td>\n",
       "      <td>0.115447</td>\n",
       "      <td>-0.392051</td>\n",
       "      <td>-0.317370</td>\n",
       "      <td>600</td>\n",
       "      <td>{u'n_estimators': 600}</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.392192</td>\n",
       "      <td>-0.317740</td>\n",
       "      <td>-0.386370</td>\n",
       "      <td>-0.318123</td>\n",
       "      <td>-0.397590</td>\n",
       "      <td>-0.316247</td>\n",
       "      <td>0.250486</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.071795</td>\n",
       "      <td>0.121869</td>\n",
       "      <td>-0.393949</td>\n",
       "      <td>-0.309765</td>\n",
       "      <td>700</td>\n",
       "      <td>{u'n_estimators': 700}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.394186</td>\n",
       "      <td>-0.310199</td>\n",
       "      <td>-0.387696</td>\n",
       "      <td>-0.310146</td>\n",
       "      <td>-0.399964</td>\n",
       "      <td>-0.308951</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.009858</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.000576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.457578</td>\n",
       "      <td>0.136421</td>\n",
       "      <td>-0.395704</td>\n",
       "      <td>-0.302705</td>\n",
       "      <td>800</td>\n",
       "      <td>{u'n_estimators': 800}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.396098</td>\n",
       "      <td>-0.303353</td>\n",
       "      <td>-0.389601</td>\n",
       "      <td>-0.303334</td>\n",
       "      <td>-0.401412</td>\n",
       "      <td>-0.301428</td>\n",
       "      <td>0.267158</td>\n",
       "      <td>0.011101</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.000903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.327075</td>\n",
       "      <td>0.135329</td>\n",
       "      <td>-0.397330</td>\n",
       "      <td>-0.295631</td>\n",
       "      <td>900</td>\n",
       "      <td>{u'n_estimators': 900}</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.397744</td>\n",
       "      <td>-0.296462</td>\n",
       "      <td>-0.391110</td>\n",
       "      <td>-0.296340</td>\n",
       "      <td>-0.403136</td>\n",
       "      <td>-0.294091</td>\n",
       "      <td>0.007025</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.001090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.179877</td>\n",
       "      <td>0.171162</td>\n",
       "      <td>-0.399316</td>\n",
       "      <td>-0.289241</td>\n",
       "      <td>1000</td>\n",
       "      <td>{u'n_estimators': 1000}</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.399859</td>\n",
       "      <td>-0.289874</td>\n",
       "      <td>-0.392669</td>\n",
       "      <td>-0.289940</td>\n",
       "      <td>-0.405420</td>\n",
       "      <td>-0.287910</td>\n",
       "      <td>0.195521</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.608235</td>\n",
       "      <td>0.191962</td>\n",
       "      <td>-0.401458</td>\n",
       "      <td>-0.283361</td>\n",
       "      <td>1100</td>\n",
       "      <td>{u'n_estimators': 1100}</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.402029</td>\n",
       "      <td>-0.283881</td>\n",
       "      <td>-0.394705</td>\n",
       "      <td>-0.283930</td>\n",
       "      <td>-0.407640</td>\n",
       "      <td>-0.282272</td>\n",
       "      <td>0.287016</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.000770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.882634</td>\n",
       "      <td>0.150381</td>\n",
       "      <td>-0.403250</td>\n",
       "      <td>-0.277381</td>\n",
       "      <td>1200</td>\n",
       "      <td>{u'n_estimators': 1200}</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.403796</td>\n",
       "      <td>-0.278086</td>\n",
       "      <td>-0.396309</td>\n",
       "      <td>-0.277795</td>\n",
       "      <td>-0.409645</td>\n",
       "      <td>-0.276262</td>\n",
       "      <td>0.170057</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        2.032167         0.024404        -0.383846         -0.366154   \n",
       "1        3.986692         0.038500        -0.385233         -0.353730   \n",
       "2        5.666521         0.053767        -0.386839         -0.343312   \n",
       "3        7.265884         0.079153        -0.388662         -0.333696   \n",
       "4        8.978239         0.081821        -0.390381         -0.325172   \n",
       "5       13.511245         0.115447        -0.392051         -0.317370   \n",
       "6       16.071795         0.121869        -0.393949         -0.309765   \n",
       "7       14.457578         0.136421        -0.395704         -0.302705   \n",
       "8       16.327075         0.135329        -0.397330         -0.295631   \n",
       "9       18.179877         0.171162        -0.399316         -0.289241   \n",
       "10      20.608235         0.191962        -0.401458         -0.283361   \n",
       "11      22.882634         0.150381        -0.403250         -0.277381   \n",
       "\n",
       "   param_n_estimators                   params  rank_test_score  \\\n",
       "0                 100   {u'n_estimators': 100}                1   \n",
       "1                 200   {u'n_estimators': 200}                2   \n",
       "2                 300   {u'n_estimators': 300}                3   \n",
       "3                 400   {u'n_estimators': 400}                4   \n",
       "4                 500   {u'n_estimators': 500}                5   \n",
       "5                 600   {u'n_estimators': 600}                6   \n",
       "6                 700   {u'n_estimators': 700}                7   \n",
       "7                 800   {u'n_estimators': 800}                8   \n",
       "8                 900   {u'n_estimators': 900}                9   \n",
       "9                1000  {u'n_estimators': 1000}               10   \n",
       "10               1100  {u'n_estimators': 1100}               11   \n",
       "11               1200  {u'n_estimators': 1200}               12   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           -0.385058           -0.367194          -0.379599   \n",
       "1           -0.385436           -0.354787          -0.380693   \n",
       "2           -0.387082           -0.344239          -0.381543   \n",
       "3           -0.389261           -0.334143          -0.383028   \n",
       "4           -0.390605           -0.325690          -0.385195   \n",
       "5           -0.392192           -0.317740          -0.386370   \n",
       "6           -0.394186           -0.310199          -0.387696   \n",
       "7           -0.396098           -0.303353          -0.389601   \n",
       "8           -0.397744           -0.296462          -0.391110   \n",
       "9           -0.399859           -0.289874          -0.392669   \n",
       "10          -0.402029           -0.283881          -0.394705   \n",
       "11          -0.403796           -0.278086          -0.396309   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            -0.366760          -0.386880           -0.364508      0.117576   \n",
       "1            -0.354470          -0.389568           -0.351932      0.115388   \n",
       "2            -0.344449          -0.391893           -0.341248      0.092624   \n",
       "3            -0.334937          -0.393697           -0.332007      0.040597   \n",
       "4            -0.325979          -0.395342           -0.323847      0.183330   \n",
       "5            -0.318123          -0.397590           -0.316247      0.250486   \n",
       "6            -0.310146          -0.399964           -0.308951      0.011846   \n",
       "7            -0.303334          -0.401412           -0.301428      0.267158   \n",
       "8            -0.296340          -0.403136           -0.294091      0.007025   \n",
       "9            -0.289940          -0.405420           -0.287910      0.195521   \n",
       "10           -0.283930          -0.407640           -0.282272      0.287016   \n",
       "11           -0.277795          -0.409645           -0.276262      0.170057   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.003701        0.003093         0.001177  \n",
       "1         0.001799        0.003626         0.001277  \n",
       "2         0.004979        0.004229         0.001462  \n",
       "3         0.003911        0.004376         0.001237  \n",
       "4         0.008654        0.004145         0.000944  \n",
       "5         0.009833        0.004582         0.000809  \n",
       "6         0.009858        0.005011         0.000576  \n",
       "7         0.011101        0.004830         0.000903  \n",
       "8         0.004344        0.004918         0.001090  \n",
       "9         0.007975        0.005220         0.000942  \n",
       "10        0.009620        0.005296         0.000770  \n",
       "11        0.006055        0.005458         0.000800  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=11,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=3,\n",
       "       param_grid={'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=<function revert_scorer_logloss at 0x1168a9b90>, verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators_array = np.linspace(10,110, 11, dtype=int)\n",
    "\n",
    "classifier = ensemble.GradientBoostingClassifier(random_state=11)\n",
    "grid = GridSearchCV(classifier, \n",
    "                    param_grid={'n_estimators': n_estimators_array},\n",
    "                    scoring=revert_scorer_logloss,\n",
    "                    n_jobs=3)\n",
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.326744</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>-0.426850</td>\n",
       "      <td>-0.424436</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10}</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.428311</td>\n",
       "      <td>-0.424150</td>\n",
       "      <td>-0.426018</td>\n",
       "      <td>-0.425377</td>\n",
       "      <td>-0.426222</td>\n",
       "      <td>-0.423780</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>0.000683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.503730</td>\n",
       "      <td>0.011224</td>\n",
       "      <td>-0.394495</td>\n",
       "      <td>-0.390335</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'n_estimators': 20}</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.396070</td>\n",
       "      <td>-0.390263</td>\n",
       "      <td>-0.392580</td>\n",
       "      <td>-0.391580</td>\n",
       "      <td>-0.394833</td>\n",
       "      <td>-0.389160</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.000989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674574</td>\n",
       "      <td>0.013052</td>\n",
       "      <td>-0.387199</td>\n",
       "      <td>-0.381121</td>\n",
       "      <td>30</td>\n",
       "      <td>{u'n_estimators': 30}</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.388899</td>\n",
       "      <td>-0.381223</td>\n",
       "      <td>-0.384317</td>\n",
       "      <td>-0.382208</td>\n",
       "      <td>-0.388381</td>\n",
       "      <td>-0.379932</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936563</td>\n",
       "      <td>0.015634</td>\n",
       "      <td>-0.385410</td>\n",
       "      <td>-0.377286</td>\n",
       "      <td>40</td>\n",
       "      <td>{u'n_estimators': 40}</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.386879</td>\n",
       "      <td>-0.377529</td>\n",
       "      <td>-0.382108</td>\n",
       "      <td>-0.378297</td>\n",
       "      <td>-0.387243</td>\n",
       "      <td>-0.376030</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.002340</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.059285</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>-0.384603</td>\n",
       "      <td>-0.374750</td>\n",
       "      <td>50</td>\n",
       "      <td>{u'n_estimators': 50}</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.385996</td>\n",
       "      <td>-0.375211</td>\n",
       "      <td>-0.381022</td>\n",
       "      <td>-0.375683</td>\n",
       "      <td>-0.386792</td>\n",
       "      <td>-0.373355</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.001005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.232308</td>\n",
       "      <td>0.018392</td>\n",
       "      <td>-0.384222</td>\n",
       "      <td>-0.372758</td>\n",
       "      <td>60</td>\n",
       "      <td>{u'n_estimators': 60}</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.385625</td>\n",
       "      <td>-0.373283</td>\n",
       "      <td>-0.380515</td>\n",
       "      <td>-0.373606</td>\n",
       "      <td>-0.386527</td>\n",
       "      <td>-0.371386</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.000979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.392025</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>-0.383982</td>\n",
       "      <td>-0.371076</td>\n",
       "      <td>70</td>\n",
       "      <td>{u'n_estimators': 70}</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.385399</td>\n",
       "      <td>-0.371727</td>\n",
       "      <td>-0.380132</td>\n",
       "      <td>-0.371859</td>\n",
       "      <td>-0.386416</td>\n",
       "      <td>-0.369643</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.001015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.605250</td>\n",
       "      <td>0.022366</td>\n",
       "      <td>-0.383944</td>\n",
       "      <td>-0.369407</td>\n",
       "      <td>80</td>\n",
       "      <td>{u'n_estimators': 80}</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.385356</td>\n",
       "      <td>-0.370298</td>\n",
       "      <td>-0.379984</td>\n",
       "      <td>-0.370000</td>\n",
       "      <td>-0.386493</td>\n",
       "      <td>-0.367922</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.777706</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>-0.383925</td>\n",
       "      <td>-0.367757</td>\n",
       "      <td>90</td>\n",
       "      <td>{u'n_estimators': 90}</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.385109</td>\n",
       "      <td>-0.368721</td>\n",
       "      <td>-0.379743</td>\n",
       "      <td>-0.368393</td>\n",
       "      <td>-0.386921</td>\n",
       "      <td>-0.366158</td>\n",
       "      <td>0.049089</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.001139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.076988</td>\n",
       "      <td>0.026656</td>\n",
       "      <td>-0.383846</td>\n",
       "      <td>-0.366154</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'n_estimators': 100}</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.385058</td>\n",
       "      <td>-0.367194</td>\n",
       "      <td>-0.379599</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.386880</td>\n",
       "      <td>-0.364508</td>\n",
       "      <td>0.025902</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.123327</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>-0.383955</td>\n",
       "      <td>-0.364799</td>\n",
       "      <td>110</td>\n",
       "      <td>{u'n_estimators': 110}</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.385144</td>\n",
       "      <td>-0.365801</td>\n",
       "      <td>-0.379553</td>\n",
       "      <td>-0.365491</td>\n",
       "      <td>-0.387167</td>\n",
       "      <td>-0.363103</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.001205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0        0.326744         0.009047        -0.426850         -0.424436   \n",
       "1        0.503730         0.011224        -0.394495         -0.390335   \n",
       "2        0.674574         0.013052        -0.387199         -0.381121   \n",
       "3        0.936563         0.015634        -0.385410         -0.377286   \n",
       "4        1.059285         0.016857        -0.384603         -0.374750   \n",
       "5        1.232308         0.018392        -0.384222         -0.372758   \n",
       "6        1.392025         0.020398        -0.383982         -0.371076   \n",
       "7        1.605250         0.022366        -0.383944         -0.369407   \n",
       "8        1.777706         0.026329        -0.383925         -0.367757   \n",
       "9        2.076988         0.026656        -0.383846         -0.366154   \n",
       "10       2.123327         0.021406        -0.383955         -0.364799   \n",
       "\n",
       "   param_n_estimators                  params  rank_test_score  \\\n",
       "0                  10   {u'n_estimators': 10}               11   \n",
       "1                  20   {u'n_estimators': 20}               10   \n",
       "2                  30   {u'n_estimators': 30}                9   \n",
       "3                  40   {u'n_estimators': 40}                8   \n",
       "4                  50   {u'n_estimators': 50}                7   \n",
       "5                  60   {u'n_estimators': 60}                6   \n",
       "6                  70   {u'n_estimators': 70}                5   \n",
       "7                  80   {u'n_estimators': 80}                3   \n",
       "8                  90   {u'n_estimators': 90}                2   \n",
       "9                 100  {u'n_estimators': 100}                1   \n",
       "10                110  {u'n_estimators': 110}                4   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           -0.428311           -0.424150          -0.426018   \n",
       "1           -0.396070           -0.390263          -0.392580   \n",
       "2           -0.388899           -0.381223          -0.384317   \n",
       "3           -0.386879           -0.377529          -0.382108   \n",
       "4           -0.385996           -0.375211          -0.381022   \n",
       "5           -0.385625           -0.373283          -0.380515   \n",
       "6           -0.385399           -0.371727          -0.380132   \n",
       "7           -0.385356           -0.370298          -0.379984   \n",
       "8           -0.385109           -0.368721          -0.379743   \n",
       "9           -0.385058           -0.367194          -0.379599   \n",
       "10          -0.385144           -0.365801          -0.379553   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            -0.425377          -0.426222           -0.423780      0.007623   \n",
       "1            -0.391580          -0.394833           -0.389160      0.011442   \n",
       "2            -0.382208          -0.388381           -0.379932      0.009743   \n",
       "3            -0.378297          -0.387243           -0.376030      0.059006   \n",
       "4            -0.375683          -0.386792           -0.373355      0.053802   \n",
       "5            -0.373606          -0.386527           -0.371386      0.018498   \n",
       "6            -0.371859          -0.386416           -0.369643      0.002456   \n",
       "7            -0.370000          -0.386493           -0.367922      0.036059   \n",
       "8            -0.368393          -0.386921           -0.366158      0.049089   \n",
       "9            -0.366760          -0.386880           -0.364508      0.025902   \n",
       "10           -0.365491          -0.387167           -0.363103      0.038265   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.001875        0.001036         0.000683  \n",
       "1         0.000993        0.001445         0.000989  \n",
       "2         0.000982        0.002049         0.000932  \n",
       "3         0.000449        0.002340         0.000942  \n",
       "4         0.000768        0.002553         0.001005  \n",
       "5         0.002069        0.002647         0.000979  \n",
       "6         0.000326        0.002754         0.001015  \n",
       "7         0.001290        0.002839         0.001057  \n",
       "8         0.000476        0.003048         0.001139  \n",
       "9         0.002296        0.003093         0.001177  \n",
       "10        0.003440        0.003220         0.001205  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
